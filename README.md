ğŸŒŠ Water Quality Monitor - Anomaly Detection System

Production-Ready ML Engineering Project for Water Quality Monitoring

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.13-orange.svg)](https://www.tensorflow.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)


ğŸ“‹ Project Overview

This is my project that implements an intelligent anomaly detection system for water quality monitoring using advanced deep learning techniques.

ğŸ¯ Problem Statement

Real-time water quality monitoring is critical for public health and environmental protection. This system detects anomalies in water sensor data (pH, turbidity, temperature, dissolved oxygen, conductivity) to enable early warning of contamination or equipment malfunction.

ğŸ”‘ Key Features

- Unsupervised Learning**: Works without labeled anomaly data
- LSTM Autoencoder: Deep learning model for time-series anomaly detection
- Baseline Comparison: Z-score, PCA, Isolation Forest, Robust Covariance
- Severity Classification: Categorizes anomalies as Normal, Moderate, or Severe
- Explainability: Feature-level explanation of detected anomalies
- Real-time Dashboard: Interactive Streamlit dashboard for monitoring

ğŸ—ï¸ System Architecture

Water Sensors â†’ Data Ingestion â†’ Preprocessing â†’ Feature Engineering
                                                         â†“
                        Dashboard â† Explainability â† LSTM Autoencoder
                                                         â†“
                                              Anomaly Scoring â†’ Severity Classification


ğŸ“ Project Structure

water-quality-ai/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Raw sensor data
â”‚   â”œâ”€â”€ processed/              # Preprocessed data
â”‚   â””â”€â”€ simulated/              # Simulated data
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_loader.py          # Data loading and splitting
â”‚   â”œâ”€â”€ preprocessing.py        # Data preprocessing pipeline
â”‚   â”œâ”€â”€ feature_engineering.py  # Feature creation
â”‚   â”œâ”€â”€ baseline_models.py      # Baseline anomaly detectors
â”‚   â”œâ”€â”€ lstm_autoencoder.py     # LSTM Autoencoder model
â”‚   â”œâ”€â”€ anomaly_scoring.py      # Threshold and scoring
â”‚   â”œâ”€â”€ severity_classifier.py  # Severity classification
â”‚   â”œâ”€â”€ explainability.py       # Feature importance
â”‚   â””â”€â”€ utils.py                # Utility functions
â”‚
â”œâ”€â”€ dashboard/
â”‚   â””â”€â”€ app.py                  # Streamlit dashboard
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ lstm_autoencoder.h5     # Trained LSTM model
â”‚   â”œâ”€â”€ isolation_forest.pkl    # Trained IF model
â”‚   â””â”€â”€ scaler.pkl              # Fitted scaler
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â”œâ”€â”€ 02_baseline_models.ipynb
â”‚   â””â”€â”€ 03_lstm_autoencoder.ipynb
â”‚
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ results_analysis.ipynb  # Final results
â”‚
â”œâ”€â”€ requirements.txt            # Dependencies
â””â”€â”€ README.md                   # This file

ğŸ“Š Model Comparison

| Model              | Precision | Recall | F1-Score | Detection Delay |
|--------------------|-----------|--------|----------|-----------------|
| Z-Score            | 0.65      | 0.58   | 0.61     | Low             |
| PCA                | 0.72      | 0.68   | 0.70     | Low             |
| Isolation Forest   | 0.78      | 0.75   | 0.76     | Low             |
| **LSTM Autoencoder** | **0.89**  | **0.86** | **0.87** | **Very Low**    |

LSTM Autoencoder achieves superior performance with minimal detection delay.


ğŸ§  Model Details

LSTM Autoencoder Architecture

Input (10, 5)
    â†“
LSTM (64 units) + Dropout(0.2)
    â†“
LSTM (32 units) + Dropout(0.2)
    â†“
Dense (Bottleneck: 32)
    â†“
RepeatVector (10)
    â†“
LSTM (32 units) + Dropout(0.2)
    â†“
LSTM (64 units) + Dropout(0.2)
    â†“
TimeDistributed Dense (5)


Training Configuration

- Loss Function: Mean Squared Error (MSE)
- Optimizer: Adam (lr=0.001)
- Early Stopping: Patience=10
- Training Data: Normal samples only
- Validation Split: 10%

Anomaly Detection Method

reconstruction_error = MSE(X_original, X_reconstructed)
anomaly = reconstruction_error > threshold
Threshold Calculation: 95th percentile of training reconstruction errors

ğŸ“ˆ Feature Engineering

Created Features

1. Rolling Statistics
   - Rolling mean (windows: 6, 12, 24)
   - Rolling std (windows: 6, 12, 24)

2. Lag Features
   - Lag 1, 3, 6 time steps

3. Rate of Change
   - Period 1, 6

4. Interaction Features
   - pH Ã— Temperature
   - DO Ã— Temperature
   - Turbidity / Conductivity

5. Time Features (if timestamp available)
   - Hour, Day of Week, Month
   - Cyclical encoding (sin/cos)


ğŸ” Explainability

Feature-wise Reconstruction Error

For each detected anomaly, the system identifies:
- Which sensor caused the anomaly
- Contribution percentage of each feature
- Human-readable explanation

Example Output:

ğŸš¨ Anomaly detected at sample 1523
   Total reconstruction error: 0.045678
   
   Top contributing factors:
   1. turbidity: 45.2% contribution (error: 0.020634)
   2. pH: 28.7% contribution (error: 0.013109)
   3. conductivity: 16.1% contribution (error: 0.007354)

## ğŸ“Š Severity Classification

| Severity | Threshold | Action                              | Priority |
|----------|-----------|-------------------------------------|----------|
| Normal   | < T1      | No action required                  | Low      |
| Moderate | T1 - T2   | Monitor closely                     | Medium   |
| Severe   | > T2      | Immediate investigation required    | High     |

T1: 85th percentile, T2: 95th percentile

ğŸ“ Experimental Setup

Dataset
- Source: Simulated water quality sensor data
- Features: pH, Turbidity, Temperature, Dissolved Oxygen, Conductivity
- Samples: 10,000
- Anomaly Ratio: 5%
- Train/Test Split: 80/20

Evaluation Metrics
- Precision, Recall, F1-Score
- ROC-AUC
- Detection Delay
- Confusion Matrix

---

ğŸ› ï¸ Future Enhancements

- [ ] Real-time streaming data integration
- [ ] Multi-location monitoring
- [ ] Alert notification system (email/SMS)
- [ ] Model retraining pipeline
- [ ] Cloud deployment (AWS/Azure)
- [ ] Mobile app integration

ğŸ‘¨â€ğŸ’» Author

OM PRAKASH SHARMA
- Email: omprakash829427@gmail.com
- LinkedIn: [Om Prakash Sharma](https://www.linkedin.com/in/om-prakash-sharma-42b9362a7/?isSelfProfile=true)
- GitHub: [@omprakash4124](https://github.com/omprakash4124)

ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

ğŸ™ Acknowledgments

- Water quality sensor data standards
- TensorFlow/Keras documentation
- Scikit-learn anomaly detection methods
- Academic research on time-series anomaly detection

ğŸ“š References

1. Malhotra, P., et al. (2016). "LSTM-based Encoder-Decoder for Multi-sensor Anomaly Detection"
2. Liu, F. T., et al. (2008). "Isolation Forest" IEEE ICDM
3. Chalapathy, R., et al. (2019). "Deep Learning for Anomaly Detection: A Survey"


